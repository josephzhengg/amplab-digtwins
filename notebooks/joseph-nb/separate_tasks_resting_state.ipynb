{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# load processed fif file\n",
    "processed_dir = os.path.join('..', '..', 'processed')\n",
    "resting_files = glob.glob(os.path.join(processed_dir, \"*resting_state*.fif\"))\n",
    "\n",
    "print(f\"Found {len(resting_files)} resting state files:\")\n",
    "for f in resting_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "# load all files\n",
    "raw_list = []\n",
    "for file_path in resting_files:\n",
    "    print(f\"\\nLoading {os.path.basename(file_path)}...\")\n",
    "    r = mne.io.read_raw_fif(file_path, preload=True)\n",
    "    raw_list.append(r)\n",
    "    print(f\"  ✓ Channels: {len(r.ch_names)}, Duration: {r.times[-1]:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2077f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract events for each raw file separately\n",
    "task_1_events_list = []\n",
    "task_2_events_list = []\n",
    "\n",
    "for raw in raw_list:\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "    \n",
    "    # Extract eyes closed events (event_id 3)\n",
    "    task_1 = events[events[:, 2] == 3]\n",
    "    task_1_events_list.append(task_1)\n",
    "    \n",
    "    # Extract eyes open events (event_id 4)\n",
    "    task_2 = events[events[:, 2] == 4]\n",
    "    task_2_events_list.append(task_2)\n",
    "\n",
    "print(f\"\\n✓ Found events:\")\n",
    "print(f\"  Eyes Closed: {sum(len(e) for e in task_1_events_list)} events\")\n",
    "print(f\"  Eyes Open: {sum(len(e) for e in task_2_events_list)} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f710c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to extract segments from multiple raw files\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def extract_and_save_segments_from_multiple(raw_list, events_list, event_name, segment_duration=1.0, output_dir='../../gan_data'):\n",
    "    \"\"\"\n",
    "    Extract EEG segments from multiple raw files and combine\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    raw_list : list of mne.Raw\n",
    "        List of raw EEG data objects\n",
    "    events_list : list of numpy arrays\n",
    "        List of event arrays, one per raw file\n",
    "    event_name : str\n",
    "        Name for this event type (e.g., 'eyes_closed', 'eyes_open')\n",
    "    segment_duration : float\n",
    "        Duration of each segment in seconds\n",
    "    output_dir : str\n",
    "        Directory to save the data\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EXTRACTING {event_name.upper()} SEGMENTS FROM {len(raw_list)} FILES\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_segments = []\n",
    "    \n",
    "    # Process each file\n",
    "    for file_idx, (raw, events) in enumerate(zip(raw_list, events_list)):\n",
    "        sfreq = raw.info['sfreq']\n",
    "        segment_samples = int(sfreq * segment_duration)\n",
    "        \n",
    "        print(f\"\\nFile {file_idx + 1}/{len(raw_list)}: {len(events)} events\")\n",
    "        \n",
    "        segments = []\n",
    "        skipped = 0\n",
    "        \n",
    "        for event in events:\n",
    "            start_sample = event[0]\n",
    "            end_sample = start_sample + segment_samples\n",
    "            \n",
    "            if end_sample <= raw.n_times:\n",
    "                segment = raw.get_data(start=start_sample, stop=end_sample)\n",
    "                segments.append(segment)\n",
    "            else:\n",
    "                skipped += 1\n",
    "        \n",
    "        if skipped > 0:\n",
    "            print(f\"  ⚠ Skipped {skipped} events (too close to end)\")\n",
    "        \n",
    "        print(f\"  ✓ Extracted {len(segments)} segments\")\n",
    "        all_segments.extend(segments)\n",
    "    \n",
    "    # Combine all segments\n",
    "    all_segments = np.array(all_segments)\n",
    "    print(f\"\\n✓ Total extracted: {len(all_segments)} segments\")\n",
    "    print(f\"  Shape: {all_segments.shape} (n_segments, n_channels, n_timepoints)\")\n",
    "    \n",
    "    # Normalize segments\n",
    "    print(\"\\nNormalizing segments...\")\n",
    "    normalized_segments = []\n",
    "    \n",
    "    for segment in all_segments:\n",
    "        mean = segment.mean(axis=1, keepdims=True)\n",
    "        std = segment.std(axis=1, keepdims=True) + 1e-8\n",
    "        normalized = (segment - mean) / std\n",
    "        normalized_segments.append(normalized)\n",
    "    \n",
    "    normalized_segments = np.array(normalized_segments).astype(np.float32)\n",
    "    print(f\"✓ Normalized: Mean={normalized_segments.mean():.4f}, Std={normalized_segments.std():.4f}\")\n",
    "    \n",
    "    # Save data in multiple formats\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 2. FIF format (MNE native - preserves all info)\n",
    "    n_segments, n_channels, n_timepoints = normalized_segments.shape\n",
    "    concatenated_data = normalized_segments.transpose(1, 0, 2).reshape(n_channels, n_segments * n_timepoints)\n",
    "    info = mne.create_info(ch_names=raw_list[0].ch_names, sfreq=raw_list[0].info['sfreq'], ch_types='eeg')\n",
    "    raw_segments = mne.io.RawArray(concatenated_data, info)\n",
    "    \n",
    "    data_path_fif = os.path.join(output_dir, f'{event_name}_segments.fif')\n",
    "    raw_segments.save(data_path_fif, overwrite=True)\n",
    "    print(f\"✓ Saved FIF: {data_path_fif}\")\n",
    "    \n",
    "    # 3. SAVE INDIVIDUAL SEGMENTS with indexes\n",
    "    individual_dir = os.path.join(output_dir, event_name + '_individual')\n",
    "    os.makedirs(individual_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"\\n✓ Saving individual segments to {individual_dir}...\")\n",
    "    for idx, segment in enumerate(normalized_segments):\n",
    "        segment_path = os.path.join(individual_dir, f'{event_name}_segment_{idx:04d}.npy')\n",
    "        np.save(segment_path, segment)\n",
    "    \n",
    "    print(f\"✓ Saved {len(normalized_segments)} individual segment files\")\n",
    "    print(f\"  Format: {event_name}_segment_0000.npy, {event_name}_segment_0001.npy, ...\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'n_segments': len(normalized_segments),\n",
    "        'n_channels': normalized_segments.shape[1],\n",
    "        'n_timepoints': normalized_segments.shape[2],\n",
    "        'sfreq': raw_list[0].info['sfreq'],\n",
    "        'segment_duration': segment_duration,\n",
    "        'ch_names': raw_list[0].ch_names,\n",
    "        'event_name': event_name,\n",
    "        'n_files': len(raw_list),\n",
    "        'individual_segments_dir': individual_dir\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(output_dir, f'{event_name}_metadata.npy')\n",
    "    np.save(metadata_path, metadata)\n",
    "    print(f\"✓ Saved metadata: {metadata_path}\")\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUMMARY: {event_name.upper()}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total segments: {metadata['n_segments']} (from {metadata['n_files']} files)\")\n",
    "    print(f\"Channels: {metadata['n_channels']}\")\n",
    "    print(f\"Timepoints per segment: {metadata['n_timepoints']}\")\n",
    "    print(f\"Sampling rate: {metadata['sfreq']} Hz\")\n",
    "    print(f\"Segment duration: {metadata['segment_duration']} sec\")\n",
    "    print(f\"\\nSaved formats:\")\n",
    "    print(f\"  • Combined NPY: {event_name}_segments.npy\")\n",
    "    print(f\"  • Combined FIF: {event_name}_segments.fif\")\n",
    "    print(f\"  • Individual segments: {individual_dir}/\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    return normalized_segments, metadata\n",
    "\n",
    "# Extract and save EYES CLOSED segments from all files\n",
    "eyes_closed_segments, eyes_closed_meta = extract_and_save_segments_from_multiple(\n",
    "    raw_list=raw_list,\n",
    "    events_list=task_1_events_list,\n",
    "    event_name='eyes_closed',\n",
    "    segment_duration=1.0\n",
    ")\n",
    "\n",
    "# Extract and save EYES OPEN segments from all files\n",
    "eyes_open_segments, eyes_open_meta = extract_and_save_segments_from_multiple(\n",
    "    raw_list=raw_list,\n",
    "    events_list=task_2_events_list,\n",
    "    event_name='eyes_open',\n",
    "    segment_duration=1.0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
