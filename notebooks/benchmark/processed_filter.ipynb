{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9de3c0b",
   "metadata": {},
   "source": [
    "# Step Two (Optional), Constrain the Channels\n",
    "In this step, you can choose to constrain the channels of your data to focus on specific areas of interest. This is particularly useful when dealing with multi-channel data where only certain channels are relevant for your analysis.\n",
    "\n",
    "With more channels, data can become noisy and harder to interpret. By constraining the channels, you can reduce this noise and improve the clarity of your results.\n",
    "\n",
    "We filtered to use the following channels:\n",
    "``` python\n",
    "extract_channels = [\n",
    "    'E1',   # AF3\n",
    "    'E32',  # AF4\n",
    "    'E8',   # F3\n",
    "    'E3',   # Fz\n",
    "    'E6',   # F4\n",
    "    'E10',  # FC3\n",
    "    'E14',  # FCz\n",
    "    'E21',  # FC4\n",
    "    'E23',  # C3\n",
    "    'E31',  # Fz\n",
    "    'E24',  # C4\n",
    "    'E47',  # CP3\n",
    "    'E53',  # CPz\n",
    "    'E86',  # CP4\n",
    "    'E55',  # P3\n",
    "    'E80'   # P4\n",
    "]\n",
    "```\n",
    "\n",
    "This can adjusted to fit your specific needs and the channels that are most relevant to your study.\n",
    "Usually a good guideline is to select channels in powers of 2 (e.g., 8, 16, 32) to maintain computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591abfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ad8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# Load all resting state files from raw directory\n",
    "raw_dir = os.path.join('..', '..', 'processed')\n",
    "\n",
    "# Find all files with \"resting_state\" in the name\n",
    "resting_files = glob.glob(os.path.join(raw_dir, \"*resting_state*.fif\"))\n",
    "\n",
    "print(f\"Found {len(resting_files)} resting state files:\")\n",
    "for f in resting_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "# load each file and store in a list\n",
    "raw_list = []\n",
    "for file_path in resting_files:\n",
    "    print(f\"\\nLoading {os.path.basename(file_path)}...\")\n",
    "    raw = mne.io.read_raw_fif(file_path, preload=True)\n",
    "    raw_list.append(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3a45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and extract channels\n",
    "extract_channels = [\n",
    "    'E1',   # AF3\n",
    "    'E32',  # AF4\n",
    "    'E8',   # F3\n",
    "    'E3',   # Fz\n",
    "    'E6',   # F4\n",
    "    'E10',  # FC3\n",
    "    'E14',  # FCz\n",
    "    'E21',  # FC4\n",
    "    'E23',  # C3\n",
    "    'E31',  # Fz\n",
    "    'E24',  # C4\n",
    "    'E47',  # CP3\n",
    "    'E53',  # CPz\n",
    "    'E86',  # CP4\n",
    "    'E55',  # P3\n",
    "    'E80'   # P4\n",
    "]\n",
    "\n",
    "# sanity check channels\n",
    "print(f\"\\nAvailable in first file: {raw_list[0].ch_names}\")\n",
    "available_set = set(raw_list[0].ch_names)\n",
    "missing = set(extract_channels) - available_set\n",
    "existing = [ch for ch in extract_channels if ch in available_set]\n",
    "\n",
    "if missing:\n",
    "    print(f\"Missing: {sorted(missing)}\")\n",
    "    print(f\"Available: {len(existing)}/16\")\n",
    "\n",
    "# filter each raw to only existing channels\n",
    "filtered_raw_list = []\n",
    "for i, raw in enumerate(raw_list, 1):\n",
    "    raw_filtered = raw.copy().pick(existing)\n",
    "    filtered_raw_list.append(raw_filtered)\n",
    "    if i % 10 == 0:\n",
    "        print(f\"Processed {i}/{len(raw_list)}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87cd3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned data\n",
    "\n",
    "processed_dir = os.path.join('..', '..', 'filtered_processed')\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# save as FIF files\n",
    "for i, r in enumerate(filtered_raw_list):\n",
    "    output_path_fif = os.path.join(processed_dir, f'resting_state_cleaned_{i}.fif')\n",
    "    r.save(output_path_fif, overwrite=True)\n",
    "    print(f\"Saved as FIF: {output_path_fif}\")\n",
    "\n",
    "# Also save channel names and sampling frequency\n",
    "for i, r in enumerate(filtered_raw_list):\n",
    "\n",
    "    metadata = {\n",
    "        'ch_names': r.ch_names,\n",
    "        'sfreq': r.info['sfreq'],\n",
    "        'n_channels': len(r.ch_names),\n",
    "        'n_times': r.n_times\n",
    "    }\n",
    "    metadata_path = os.path.join(processed_dir, f'resting_state_metadata{i}.npy')\n",
    "    np.save(metadata_path, metadata)\n",
    "    print(f\"Saved metadata: {metadata_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
