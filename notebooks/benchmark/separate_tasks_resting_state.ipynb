{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb9f73b8",
   "metadata": {},
   "source": [
    "# Step 3, Separating Tasks and Resting State Data\n",
    "\n",
    "In this step, we will separate the task-related data from the resting state data in our EEG recordings. This is crucial for focused analysis on specific cognitive tasks or resting state brain activity. Our focus is to segment the data based on event markers that indicate the start and end of tasks. These instructions are `instructed_toCloseEyes` and `instructed_toOpenEyes` for resting state data, and `task_start` and `task_end` for task-related data.\n",
    "\n",
    "Here, we segment the data into two distinct sets, one for closed-eyes resting state and another for open-eyes resting state. This allows us to analyze the brain activity during these specific conditions separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fb0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2468c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load processed fif file\n",
    "processed_dir = os.path.join('..', '..', 'filtered_processed') # this can also be switch to 'processed' if 128 channels are preferred\n",
    "resting_files = glob.glob(os.path.join(processed_dir, \"*resting_state*.fif\"))\n",
    "\n",
    "print(f\"Found {len(resting_files)} resting state files:\")\n",
    "for f in resting_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "# load all files\n",
    "raw_list = []\n",
    "for file_path in resting_files:\n",
    "    print(f\"Loading {os.path.basename(file_path)}...\")\n",
    "    r = mne.io.read_raw_fif(file_path, preload=True)\n",
    "    raw_list.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2077f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract events for each raw file separately using event names\n",
    "task_1_events_list = []  # Eyes CLOSED\n",
    "task_2_events_list = []  # Eyes OPEN\n",
    "\n",
    "for raw in raw_list:\n",
    "    events, event_dict = mne.events_from_annotations(raw)\n",
    "    \n",
    "    close_eyes_id = event_dict.get('instructed_toCloseEyes')\n",
    "    open_eyes_id = event_dict.get('instructed_toOpenEyes')\n",
    "    \n",
    "    # extract eyes CLOSED events using event name\n",
    "    task_1 = events[events[:, 2] == close_eyes_id]\n",
    "    task_1_events_list.append(task_1)\n",
    "    \n",
    "    # extract eyes OPEN events using event name\n",
    "    task_2 = events[events[:, 2] == open_eyes_id]\n",
    "    task_2_events_list.append(task_2)\n",
    "\n",
    "print(f\"  Eyes Closed (instructed_toCloseEyes): {sum(len(e) for e in task_1_events_list)} events\")\n",
    "print(f\"  Eyes Open (instructed_toOpenEyes): {sum(len(e) for e in task_2_events_list)} events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f710c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to extract segments from multiple raw files\n",
    "\n",
    "def extract_and_save_segments_from_multiple(raw_list, events_list, event_name, segment_duration=1.0, output_dir='../../gan_data'):\n",
    "    all_segments = []\n",
    "    \n",
    "    for file_idx, (raw, events) in enumerate(zip(raw_list, events_list)):\n",
    "        sfreq = raw.info['sfreq']\n",
    "        segment_samples = int(sfreq * segment_duration)\n",
    "        \n",
    "        print(f\"\\nFile {file_idx + 1}/{len(raw_list)}: {len(events)} events\")\n",
    "        \n",
    "        segments = []\n",
    "        \n",
    "        for event in events:\n",
    "            start_sample = event[0]\n",
    "            end_sample = start_sample + segment_samples\n",
    "            \n",
    "            if end_sample <= raw.n_times:\n",
    "                segment = raw.get_data(start=start_sample, stop=end_sample)\n",
    "                segments.append(segment)\n",
    "        \n",
    "        all_segments.extend(segments)\n",
    "    \n",
    "    # combine segments\n",
    "    all_segments = np.array(all_segments)\n",
    "    \n",
    "    # normalize segments\n",
    "    normalized_segments = []\n",
    "    \n",
    "    for segment in all_segments:\n",
    "        \n",
    "        mean = segment.mean()\n",
    "        std = segment.std() + 1e-8\n",
    "        normalized = (segment - mean) / std\n",
    "    \n",
    "        normalized_segments.append(normalized)\n",
    "    \n",
    "    normalized_segments = np.array(normalized_segments).astype(np.float32)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    n_segments, n_channels, n_timepoints = normalized_segments.shape\n",
    "    concatenated_data = normalized_segments.transpose(1, 0, 2).reshape(n_channels, n_segments * n_timepoints)\n",
    "    info = mne.create_info(ch_names=raw_list[0].ch_names, sfreq=raw_list[0].info['sfreq'], ch_types='eeg')\n",
    "    raw_segments = mne.io.RawArray(concatenated_data, info)\n",
    "    \n",
    "    data_path_fif = os.path.join(output_dir, f'{event_name}_segments.fif')\n",
    "    raw_segments.save(data_path_fif, overwrite=True)\n",
    "    print(f\"Saved FIF: {data_path_fif}\")\n",
    "    \n",
    "    individual_dir = os.path.join(output_dir, event_name + '_individual')\n",
    "    os.makedirs(individual_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Saving individual segments to {individual_dir}...\")\n",
    "    for idx, segment in enumerate(normalized_segments):\n",
    "        segment_path = os.path.join(individual_dir, f'{event_name}_segment_{idx:04d}.npy')\n",
    "        np.save(segment_path, segment)\n",
    "    \n",
    "    print(f\"Saved {len(normalized_segments)} individual segment files\")\n",
    "    print(f\"Format: {event_name}_segment_0000.npy, {event_name}_segment_0001.npy, ...\")\n",
    "    \n",
    "    # save metadata\n",
    "    metadata = {\n",
    "        'n_segments': len(normalized_segments),\n",
    "        'n_channels': normalized_segments.shape[1],\n",
    "        'n_timepoints': normalized_segments.shape[2],\n",
    "        'sfreq': raw_list[0].info['sfreq'],\n",
    "        'segment_duration': segment_duration,\n",
    "        'ch_names': raw_list[0].ch_names,\n",
    "        'event_name': event_name,\n",
    "        'n_files': len(raw_list),\n",
    "        'individual_segments_dir': individual_dir\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(output_dir, f'{event_name}_metadata.npy')\n",
    "    np.save(metadata_path, metadata)\n",
    "    print(f\"Saved metadata: {metadata_path}\")\n",
    "    \n",
    "    return normalized_segments, metadata\n",
    "\n",
    "# extract and save EYES CLOSED segments from all files\n",
    "eyes_closed_segments, eyes_closed_meta = extract_and_save_segments_from_multiple(\n",
    "    raw_list=raw_list,\n",
    "    events_list=task_1_events_list,\n",
    "    event_name='eyes_closed',\n",
    "    segment_duration=1.0\n",
    ")\n",
    "\n",
    "# extract and save EYES OPEN segments from all files\n",
    "eyes_open_segments, eyes_open_meta = extract_and_save_segments_from_multiple(\n",
    "    raw_list=raw_list,\n",
    "    events_list=task_2_events_list,\n",
    "    event_name='eyes_open',\n",
    "    segment_duration=1.0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
